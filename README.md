<html>
<head>
	<title>My CV</title>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta http-equiv="Generator" content="CV Maker - https://cvmkr.com/" />
	<style type="text/css">
		body {
			background: #f0f0f0;
			margin: 0;
			padding: 0;
			
			font-family: Georgia, serif, 'Trebuchet MS';
			line-height: 20px;
			font-size: 14px;

			color: #222;
		}

		h1, h2, h3, h4 {
			margin: 0 0 15px 0;
			padding: 0;
		}
		h1 {
			font-size: 400%;
		}
		h2 {
			font-size: 210%;
		}
		h3 {
			font-size: 130%;
		}
		
		p {
			margin: 0 0 10px 0;
		}
		
		ul {
			list-style-type: circle;
		}
		li {
			margin-bottom: 5px;
		}
		a {
			color: #222;
		}
		/* ________________________________________________________ */
		.rtl {
			direction: rtl;
		}
		.clear {
			clear: both;
		}

		#main {
			background: #fff;
			width: 900px;
			padding: 35px;
			margin: 0 auto 15px auto;
			overflow: hidden;
			
			box-shadow: 0 0 6px #ccc;
		}
		
		#title {
			line-height: 42px;
			margin: 0px 0 15px 0;
			font-weight: normal;
			text-align: center;
		}
		
		#credit {
			margin-bottom: 20px;
			font-size: 15px;
			color: #999;
			text-align: center;
		}
			#credit a {
				color: #999;
			}
		
		p label {
			font-weight: bold;
			
			font-size: 110%;
			margin-right: 10px;
		}
			p label span.colon {
				display: inline;
			}

		
		.section {
			margin-bottom: 30px;
		}
		
		.item {
			margin: 0 0 20px 0;
		}

		/*  _____________________________ */
		.basic-info {
			margin: 0 auto 30px auto;
			width: 80%;
			overflow: hidden;
			text-align: center;
		}
		.basic-info p {
			margin: 0;
		}
		.basic-info .dot {
			display: inline;
			font-size: 18px;
			margin: 0 10px;
		}
		
		.section .title {
			text-transform: uppercase;
			font-size: 150%;
			text-align: center;
			border-bottom: 1px solid #ccc;
			padding-bottom: 10px;
		}
			.section .set h3 {
				margin: 0;
			}
		.section span.value {
			display: block;
		}
		.section h3 span.l, .section span.r {
			width: 49%;
			float: left;
		}
			.section span.r {
				float: right;
				text-align: right;
			}
			.section-education .school,
			.section-work .job_title {
				font-size: 100%;
				display: block;
				margin: 5px 0 5px 0;
				font-style: italic;
			}

		/* ___ photo ___ */
		#photo {
			width: 160px;
			height: 200px;
			overflow: hidden;
			float: left;
			margin-top: 8px;
			border-radius: 4px;
		}
		#photo img {
			width: 100%;
			height: auto;
		}
		.header.photo {
			margin-left: 190px;
		}
		.header.photo #title {
			text-align: left;
		}
		.header.photo .basic-info {
			float: none;
			padding: 0;
			width: auto;
			text-align: left;
		}

		@media screen and (max-width: 950px) {
			body {
				background: #fff;
			}
			#main {
				box-shadow: none;
				padding: 0;
				padding: 5px;
			}
		}
	</style>
</head>
<body class="lang-en ">

<div id="main">
			<div id="photo">
			<img src="https://s3-eu-west-1.amazonaws.com/files1.cvmkr.com/ce1660_4349985_12660298.jpg" alt="" />
		</div>
		<div class="header photo">
	
	<h1 id="title">Hao Shi</h1>
	<div class="basic-info section">
		<div class="set">
						<p class="email">
											E-mail <span class="dot">&sect;</span> shi@sap.ist.i.kyoto-u.ac.jp / hshi.cca@gmail.com<br />
					
					
											Phone <span class="dot">&sect;</span> +86 15222877881<br />
									</p>
			
							<p class="address">
											Address <span class="dot">&sect;</span>
										Sakyo-ku, Kyoto 606-8501, Japan (606-8501, 京都市左京区吉田本町総合研究7 号館4 階)				</p>
			
			<div class="clear"> </div>
		</div><!-- set //-->
		<div class="clear"> </div>
	</div><!-- basic-info //-->

			</div><div class="clear"> </div>
	
		
			<div class="section section-1620313811176">
			<h2 class="title">About Me</h2>
			<div class="set">
							<div class="item">
								<span class="info"><p><span>I am Hao Shi (史昊), in</span> <span><a>Speech and Audio Processing Lab.</a></span><span>, Kyoto University, Japan. </span>I am a Ph.D. student from <span><a>Graduate School of Informatics</a></span>, <span><a>Kyoto university</a></span>, Japan, where I studied under the supervision of Prof. Tatsuya Kawahara. I received the Master’s degree from <span><a>College of Intelligence and Computing</a></span>, <span><a>Tianjin University</a></span>, where I studied under the supervision of Prof. Longbiao Wang. I receive bachelor’s degree from <span><a>the school of information science and technology</a></span>, <span><a>Southwest Jiaotong University</a></span>, Chengdu, China, in 2018.</p><p>My main research interests (not limited) are <em>robust automatic speech recognition</em>, <em>speech enhancement/separation</em>, <em>speech signal processing</em>.</p><p>I like travelling, playing basketball, listening to music, playing the piano. </p></span>
							</div>
						</div>
			<div class="clear"> </div>
		</div>
			<div class="section section-1620314201577">
			<h2 class="title">Research Interests</h2>
			<div class="set">
							<div class="item">
								<span class="info"><h3><span><span style="font-weight:normal;">Automatic Speech Recognition</span></span></h3><div><ul><li><span>Robust Automatic Speech Recognition</span></li><li><span>End-to-end Automatic Speech Recognition</span></li></ul><h3><span><span style="font-weight:normal;"><br /></span></span></h3><h3><span><span style="font-weight:normal;">Speech Enhancement</span></span></h3><div><ul><li><span>Spectrograms Fusion-based Frequency Enhancement</span></li></ul></div><h3><span><span style="font-weight:normal;"><br /></span></span></h3><h3><span><span style="font-weight:normal;">Speech Separation</span></span></h3></div><div><ul><li><span>Blind Speech Separation</span></li></ul></div></span>
							</div>
						</div>
			<div class="clear"> </div>
		</div>
			<div class="section section-education">
			<h2 class="title">Education</h2>
			<div class="set">
						<div class="item">
							<h3><span class="course l">Ph.D.</span>
						<span class="date r">04, 2021 &mdash; Present</span>
							</h3>
							<div class="clear"> </div>
							<span class="school">Kyoto University, Kyoto, Japan</span><div class="info"><div><ul><li><span><span>Speech and Audio Processing Laboratory, Department of Intelligence Science and Technology, School of</span></span></li></ul></div><div><span><span>Informatics</span></span></div><div><ul><li>Major: Computer Science and Technology</li></ul></div><div><ul><li><span>Supervisor: Prof. Tatsuya Kawahara</span></li></ul></div></div><span class="clear"> </span>
						</div>
						
						<div class="item">
							<h3><span class="course l">M.Phil.</span>
						<span class="date r">09, 2018 &mdash; 01, 2021</span>
							</h3>
							<div class="clear"> </div>
							<span class="school">Tianjin University, Tianjin, China</span><div class="info"><ul><li><span>Tianjin Key Laboratory of Cognitive Computing and Application, College of Intelligence and Computing</span></li><li><span>Major: Computer Science and Technology</span></li><li><span>Supervisor: Prof. Longbiao Wang</span></li></ul></div><span class="clear"> </span>
						</div>
						
						<div class="item">
							<h3><span class="course l">B.Sc.</span>
						<span class="date r">09, 2014 &mdash; 06, 2018</span>
							</h3>
							<div class="clear"> </div>
							<span class="school">Southwest Jiaotong University, Sichuan, China</span><div class="info"><ul><li><span>The School of Information Science and Technology</span></li><li><span>Major: Computer Science and Technology</span></li></ul></div><span class="clear"> </span>
						</div>
						</div>
			<div class="clear"> </div>
		</div>
			<div class="section section-work">
			<h2 class="title">Working Experience</h2>
			<div class="set">
								<div class="item">
									<h3><span class="company l">Tianjin University</span>
							<span class="date r">05, 2021 &mdash; Present</span>
								</h3>
								<div class="clear"> </div>
								<span class="job_title">Research Assistant</span><div class="info"><ul><li><span>Engaged in automatic speech recognition and speech enhancement research</span></li></ul></div><div class="clear"> </div>
								</div>
							
								<div class="item">
									<h3><span class="company l">INTERSPEECH</span>
							<span class="date r">09, 2020 &mdash; 10, 2020</span>
								</h3>
								<div class="clear"> </div>
								<span class="job_title">Volunteer</span><div class="info"><ul><li><span>Guide and organize the report of multiple sub-topics</span></li></ul></div><div class="clear"> </div>
								</div>
							</div>
			<div class="clear"> </div>
		</div>
	
	
			<div class="section section-1620315088266">
			<h2 class="title">Publications</h2>
			<div class="set">
			<div class="item">
<span class="info">
	<h3><span>Conference Papers, First Author</span></h3>
	<div><div><ol>
<li><span><span style="font-weight:bold;"><u>H. Shi</u></span>, L. Wang, M. Ge, S. Li, J. Dang, “Spectrograms Fusion with Minimum Difference Masks Estimation for Monaural Speech Dereverberation,” in Proc. of ICASSP, 2020, pp. 7544-7548. (<a href="pdf/0007539.pdf"><u>PDF File</u></a>, <a href="videos/ICASSP2020-3378-SPECTROGRAMS FUSION WITH MINIMUM DIFFERENCE MASKS ESTIMATION FOR MONAURAL SPEECH DEREVERBERATION-Hao Shi.mp4"><u>Video</u></a>)</span></li>
<li><span style="font-weight:bold;"><u>H. Shi</u></span>, L. Wang, S. Li, C. Ding, M. Ge, N. Li, J. Dang, H. Seki, “Singing Voice Extraction with Attention based Spectrograms Fusion,” in Proc. of Interspeech, 2020, pp. 2412-2416. (<a href="pdf/Wed-1-11-1.pdf"><u>PDF File</u></a>, <a href="videos/1043_paper_Hao Shi_Singing Voice Extraction with Attention based Spectrograms Fusion.mp4"><u>Video</u></a>)</li>
</ol></div></div><div><span><br/></span></div>
	
<h3><span>Conference Papers, Co-Author</span></h3>
<div><ol>
<li>L. Qiang, <span style="font-weight:bold;"><u>H. Shi</u></span>, M. Ge, H. Yin, N. Li, L. Wang, S. Li J. Dang, “Speech Dereverberation Based on Scale-aware Mean Square Error Loss,” in Proc. of ICONIP, 2021, pp. xxxx-xxxx. (<span style="font-weight:bold;"><u>Joint first author</u></span>, <a href="pdf/SaSD.pdf"><u>PDF File</u></a>)</li>
<li>M. Ge, L. Wang, N. Li, <span style="font-weight:bold;"><u>H. Shi</u></span>, J. Dang, X. Li, “xxxxxxxx,” in Proc. of ICONIP, 2021, pp. xxxx-xxxx. (<span style="font-weight:bold;"><u>Joint first author</u></span>, <a href="pdf/1477.pdf"><u>PDF File</u></a>)</li>
<li>M. Ge, L. Wang, N. Li, <span style="font-weight:bold;"><u>H. Shi</u></span>, J. Dang, X. Li, “Environment-dependent attention-driven recurrent convolutional neural network for robust speech enhancement,” in Proc. of Interspeech, 2019, pp. 3153-3157. (<a href="pdf/1477.pdf"><u>PDF File</u></a>)</li>
</ol></div></span>
							</div>
						</div>
			<div class="clear"> </div>
		</div>
		
</div>
	
</body>
</html>
